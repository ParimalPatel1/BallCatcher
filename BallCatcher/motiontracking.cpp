//motionTracking.cpp

//Written by  Kyle Hounslow, December 2013

//Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software")
//, to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, 
//and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

//The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

//THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER 
//LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
//IN THE SOFTWARE.

#include <opencv\cv.h>
#include <opencv\highgui.h>
#include  <opencv2\opencv.hpp>
//#include  <opencv2\videoio.hpp>
#include <Windows.h>
#include <ctime>


using namespace cv;
using namespace std;
// START GLOBALS
//our sensitivity value to be used in the absdiff() function
const static int SENSITIVITY_VALUE = 20;
//size of blur used to smooth the intensity image output from absdiff() function
const static int BLUR_SIZE = 10;
//we'll have just one object to search for
//and keep track of its position.
int trackedObject[2] = { 0,0 };
//bounding rectangle of the object, we will use the center of this as its position.
Rect objectBoundingRectangle = Rect(0, 0, 0, 0);
vector<int> compression_params;
int imagecount = 0;
int imagecount2 = 0;
#define RESOLUTION Size(640,480)
#define BufferSize 2
Point pointlist[10000];
Point pointlist2[10000];
int airtime_clock = 0;
int airtime_clock2 = 0;
bool trackingEnabled = false;

Mat frame; //current frame
Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
int keyboard; //input from keyboard
// END GLOBALS
template <class type>
class CircularBuffer
{
public:
	CircularBuffer(int buffersize1, string name, int pixelformat) {
		if ((buffersize1 < 1) || (buffersize1 > 100000))// check parameters
		{
			cout << "Error with buffersize of " << name;
			Sleep(300000); // how to return from constructor to stop bad init?
		}
		// initialize class variables
		buffersize = buffersize1;
		bufferend = buffersize;
		current_frame = bufferstart;
		previous_frame = bufferend - 1;
		next_frame = bufferstart + 1;
		buffer = new type[buffersize];//(RESOLUTION, CV_8UC3);
		switch (pixelformat) {
		case 0:
			for (int i = 0; i < buffersize; i++)
				buffer[i] = Mat(RESOLUTION, CV_8UC3);
			break;

		case 1:
			for (int i = 0; i < buffersize; i++)
				buffer[i] = Mat(RESOLUTION, CV_8UC1);
			break;
		}


		buffername = name;
	};
	~CircularBuffer() {
		delete buffer;
	};

	type* buffer;
	type* current_ptr;
	type* previous_ptr;
	type* next_ptr;
/*	int initialize(type source) // initialize the 1st element of the buffer to get things rolling
	{
		buffer[bufferstart] = source;
		if (buffersize > 1)
		{
			buffer
		}
	} */

	type current()
	{
		current_ptr = &buffer[current_frame];
		return *current_ptr;
	}
	type previous()
	{
		previous_ptr = &buffer[previous_frame];
		return *previous_ptr;
	}
	type increment()
	{
		//previous_frame = current_frame; // current frame about to be updated, so save
		//current_frame = current_frame + 1 == bufferend ? bufferstart : current_frame + 1;
		//next_frame = current_frame + 1 == bufferend ? bufferstart : current_frame + 1;
		circulate(previous_frame);
		circulate(current_frame);
		circulate(next_frame);
		return current();
	}

	void set(type &source)
	{
		buffer[current_frame] = source;
	}


	void copythis(type &copy)
	{
		buffer[current_frame].copyTo(copy);
	}

	void diffthis(type &diff)
	{
		absdiff(buffer[current_frame], buffer[previous_frame],diff);
	}

protected:
private:
	int buffersize = 1;
	int previous_frame = 0;
	int current_frame = 0;
	int next_frame = 0;
	int bufferstart = 0;
	int bufferend = buffersize;
	int source = 0;
	string buffername = "Beef";
	void circulate(int &a)
	{
		a = a + 1 == bufferend ? bufferstart : a + 1;
	}

};


template <class type>
class ImagePipeline
{
public:
	CircularBuffer<type> a;

protected:

private:

};

//int to string helper function
string intToString(int number) {

	//this function has a number input and string output
	std::stringstream ss;
	ss << number;
	return ss.str();
}
 // finds moving objecs in an image
int searchForMovement(Mat &thresholdImage, Mat &movingobjects, int camera = 1) {
	bool objectDetected = false;
	//these two vectors needed for output of findContours
	vector< vector<Point> > contours;
	vector<Vec4i> hierarchy;
	//find contours of filtered image using openCV findContours function
	//findContours(temp,contours,hierarchy,CV_RETR_CCOMP,CV_CHAIN_APPROX_SIMPLE );// retrieves all contours
	findContours(thresholdImage, contours, hierarchy, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);// retrieves external contours

	/// Find the rotated rectangles and ellipses for each contour
	vector<RotatedRect> minRect(contours.size());
	vector<RotatedRect> minEllipse(contours.size());

	//if contours vector is not empty, we have found some objects
	if (contours.size() > 0)
	{
		//the largest contour is found at the end of the contours vector
		//we will simply assume that the biggest contour is the object we are looking for.
		vector< vector<Point> > largestContourVec;
		largestContourVec.push_back(contours.at(contours.size() - 1));
		//make a bounding rectangle around the largest contour then find its centroid
		//this will be the object's final estimated position.
		objectBoundingRectangle = boundingRect(largestContourVec.at(0));
		if (objectBoundingRectangle.area() > 30) // filter out more noise between frames // RESOLUTION DEPENDANT 
		{
			int xpos = objectBoundingRectangle.x + objectBoundingRectangle.width / 2;
			int ypos = objectBoundingRectangle.y + objectBoundingRectangle.height / 2;
//			Mat distance;
	//		magnitude(xpos, ypos, distance);
	//		distance.at<uchar>(xpos, ypos);
			//distance.at
			if (trackingEnabled) 
			{
				if (camera == 1)
				{
					trackedObject[0] = xpos;
					trackedObject[1] = ypos;
					pointlist[imagecount] = Point(xpos, ypos); //.at(imagecount,imagecount);
					circle(movingobjects, pointlist[imagecount], 20, Scalar(0, 255, 0), 2);
					if (imagecount == 0)
					{
						airtime_clock = clock(); // start timer for first point
						putText(movingobjects, "Time(ms): 0", pointlist[imagecount], 1, 1, Scalar(255, 0, 0), 2);
					}
					else
					{
						int timelaspe = clock() - airtime_clock;
						putText(movingobjects, "Time(ms): " + to_string(timelaspe), pointlist[imagecount], 1, 1, Scalar(255, 0, 0), 2);
					}
					//putText(TrackerImage, "Tracking object at (" + intToString(xpos) + "," + intToString(ypos) + ")", pointlist[imagecount], 1, 1, Scalar(255, 0, 0), 2);
					if (imagecount > 0)
					{
						line(movingobjects, pointlist[imagecount - 1], pointlist[imagecount], Scalar(0, 255, 0), 2);
					}
					imagecount++;
				}
				if (camera == 2)
				{
					pointlist2[imagecount2] = Point(xpos, ypos); //.at(imagecount,imagecount);
					circle(movingobjects, pointlist2[imagecount2], 20, Scalar(0, 255, 0), 2);
					if (imagecount == 0)
					{
						airtime_clock2 = clock(); // start timer for first point
						putText(movingobjects, "Time(ms): 0", pointlist2[imagecount2], 1, 1, Scalar(255, 0, 0), 2);
					}
					else
					{
						int timelaspe = clock() - airtime_clock2;
						putText(movingobjects, "Time(ms): " + to_string(timelaspe), pointlist2[imagecount2], 1, 1, Scalar(255, 0, 0), 2);
					}
					//putText(TrackerImage, "Tracking object at (" + intToString(xpos) + "," + intToString(ypos) + ")", pointlist[imagecount], 1, 1, Scalar(255, 0, 0), 2);
					if (imagecount > 0)
					{
						line(movingobjects, pointlist[imagecount - 1], pointlist[imagecount], Scalar(0, 255, 0), 2);
					}
					imagecount++;
				}
			}
			return 1;
		}
		return 0; // largest object is too small probably just noise
	}

	else // no object detected
		return 0;
}

/*for (int i = 0; i < contours.size(); i++) /////// MOVE ELSEWHERE
{
if (contours[i].size() > 20 && contours[i].size() < 300)
{
minEllipse[i] = fitEllipse(Mat(contours[i]));
}
//minEllipse.at(0).
}
for (int i = 0; i < contours.size(); i++)
{
//	drawContours(movingobjects, contours,
//	i, Scalar(40,100,55));
ellipse(movingobjects, minEllipse[i], Scalar(255, 255, 0));
}
*/

//update the objects positions by changing the 'theObject' array values
/*	theObject[0] = xpos, theObject[1] = ypos;
int x = theObject[0];
int y = theObject[1];
//draw some crosshairs around the object

line(TrackerImage, Point(x, y), Point(x, y - 25), Scalar(0, 255, 0), 2);
line(TrackerImage, Point(x, y), Point(x, y + 25), Scalar(0, 255, 0), 2);
line(TrackerImage, Point(x, y), Point(x - 25, y), Scalar(0, 255, 0), 2);
line(TrackerImage, Point(x, y), Point(x + 25, y), Scalar(0, 255, 0), 2);
*/
//write the position of the object to the screen	
//imshow("TrackerImage", TrackerImage);
//imwrite("trackingH"+intToString(imagecount)+".png", cameraFeed, compression_params);


int Algorithim1(Mat GraySource1, Mat GraySource2, Mat &thresholdImage) {
	Mat differenceImage;
	Mat movingobjects;

	GaussianBlur(GraySource1, GraySource1, Size(9, 9), 2, 2);
	//perform frame differencing with the sequential images. 
	absdiff(GraySource1, GraySource2, differenceImage);
	//threshold intensity image at a given sensitivity value
	threshold(differenceImage, thresholdImage, SENSITIVITY_VALUE, 255, THRESH_BINARY);
	//blur the image to get rid of the noise. This will output an intensity image
	blur(thresholdImage, thresholdImage, Size(BLUR_SIZE, BLUR_SIZE));
	//threshold again to obtain binary image from blur output
	threshold(thresholdImage, thresholdImage, SENSITIVITY_VALUE, 255, THRESH_BINARY);

	return 0;
}

int main() {
	// START DECLARATIONS
	//some boolean variables for added functionality
	bool objectDetected = false;
	//these two can be toggled by pressing 'd' or 't'
	bool debugMode = false;
	//pause and resume code
	bool pause = false;

	Mat differenceImage;
	Mat thresholdImage =  Mat(RESOLUTION, CV_8UC1);
	Mat thresholdImage2 =  Mat(RESOLUTION, CV_8UC1);
	Mat movingobjects = Mat(RESOLUTION, CV_8UC3);
	Mat movingobjects2 = Mat(RESOLUTION, CV_8UC3);
	Mat* contour_drawing; //=  new Mat Mat::create(RESOLUTION, CV_8UC3);

	VideoCapture capture;
	VideoCapture capture2;
	
	Point textcenter1(100, 50); // text variables start
	Point textcenter2(100, 100);
	Point textcenter3(100, 150);
	int fontFace = FONT_HERSHEY_SCRIPT_SIMPLEX;
	double fontScale = 1;
	int thickness = 2; // text variables end

	unsigned int current_time = 1;
	float start_time = clock(); // timer variable
	unsigned int last_time = clock();
	unsigned int framecounter = 0;
	int frame_start = 0;
	float fps;
	const string filepath = "test.avi"; //C:\Users\Benjamin\Desktop
	VideoWriter output_cap;

	CircularBuffer<Mat> RGB_Buffer(50, "RGB_Buffer",0); // only 50 right now
	CircularBuffer<Mat> RGB_Buffer2(50, "RGB_Buffer2",0);
	CircularBuffer<Mat> Gray_Buffer(50, "Gray_Buffer",1);
	CircularBuffer<Mat> Gray_Buffer2(50, "Gray_Buffer2",1);
//END DECLARATIONS

// START INIT
	//create Background Subtractor objects
	pMOG2 = createBackgroundSubtractorMOG2 (30, 16.0, false);//MOG2 approach
	//pMOG2 = createBackgroundSubtractorKNN(500, 400.0, false);
	//namedWindow("Hough Circle Transform Demo", CV_WINDOW_AUTOSIZE);
	capture.open(701); // 700 -> directshow + index, index 0 for laptop webcam, 1 for usb webcam usually
//	Sleep(500);
	if (!capture.isOpened()) {
		cout << "ERROR ACQUIRING VIDEO FEED\n";
		getchar();
		return -1;
	}

	capture2.open(702); //"http://umd:umd@192.168.0.101/video.cgi?.mjpg"
	if (!capture2.isOpened()) {
		cout << "ERROR ACQUIRING VIDEO FEED\n";
		getchar();
		return -1;
	}
	//capture.set(CV_CAP_PROP_FOURCC, CV_FOURCC('M', 'J', 'P', 'G')); // doesn't set
	capture.set(CV_CAP_PROP_FRAME_WIDTH, RESOLUTION.width); // 1280 for intergrated webcam, 1080 for external webcam
	capture.set(CV_CAP_PROP_FRAME_HEIGHT, RESOLUTION.height);
	capture.set(CV_CAP_PROP_FPS, 30); // changes property but not camera fps 
	//capture.set(CV_CAP_PROP_EXPOSURE, 99); // does nothing
	capture2.set(CV_CAP_PROP_FRAME_WIDTH, RESOLUTION.width); // 1280 for intergrated webcam, 1080 for external webcam
	capture2.set(CV_CAP_PROP_FRAME_HEIGHT, RESOLUTION.height);
	capture2.set(CV_CAP_PROP_FPS, 30); // changes property but not camera fps 

	// First initialize to get at least one previous frame
	while (!capture.read(RGB_Buffer.increment()));
	while (!capture2.read(RGB_Buffer2.increment()));
	cvtColor(RGB_Buffer.current(), Gray_Buffer.increment(), COLOR_BGR2GRAY);
	cvtColor(RGB_Buffer2.current(), Gray_Buffer2.increment(), COLOR_BGR2GRAY);


	int debug = output_cap.open(filepath,
		CV_FOURCC_MACRO('M','J','P','G'), //YUYV
	capture.get(CV_CAP_PROP_FPS),
	Size(capture.get(CV_CAP_PROP_FRAME_WIDTH),
		capture.get(CV_CAP_PROP_FRAME_HEIGHT)),true);
	 Sleep(100);
	 if (!output_cap.isOpened())
	 {
		 cout << "!!! Output video could not be opened" << debug << "\n" <<
			 capture.get(CV_CAP_PROP_FPS) << "\n" <<
			 capture.get(CV_CAP_PROP_FRAME_HEIGHT) << "\n" <<
			 capture.get(CV_CAP_PROP_FRAME_WIDTH) << endl;
		 return -1;
	 }
 // END INIT
	while (1) { // capture and process loop
		fps = 1000 / (1 + clock() - last_time);
		last_time = clock();

		//capture.read(image_array[toggle]);
		capture.grab();
		capture2.grab();
		capture.retrieve(RGB_Buffer.increment());
		capture2.retrieve(RGB_Buffer2.increment());

		cvtColor(RGB_Buffer.current(), Gray_Buffer.increment(), COLOR_BGR2GRAY);
		cvtColor(RGB_Buffer2.current(), Gray_Buffer2.increment(), COLOR_BGR2GRAY);

		
		//pMOG2->apply(Gray_Buffer.current(), thresholdImage);
		Algorithim1(Gray_Buffer.current(), Gray_Buffer.previous(), thresholdImage);
		Algorithim1(Gray_Buffer2.current(), Gray_Buffer2.previous(), thresholdImage2);



	//	*contour_drawing = Scalar(0,0,0);
		//searchForMovement(*thresholdImage, *grayImage1, *contour_drawing);
//		if(searchForMovement(*thresholdImage, *grayImage1, 1) == 1 && trackingEnabled)
		//	output_cap.write(TrackerImage); // tracking en
			//update the background model

		/// Apply the erosion operation
	//	erode(*grayImage1, erosion_dst, erode_element);

		/// Apply the dilation operation
	//	dilate(erosion_dst, dilation_dst, dilation_element);
	//	imshow("Dilation Demo", dilation_dst);


		
	//	imshow("MOG2", fgMaskMOG2);

		cout << "FPS: " << fps << endl; // faster than draw??
		

		//imshow("movingobjects", *contour_drawing);
		//putText(*grayImage1, "FPS: " + to_string(fps), textcenter3, fontFace, fontScale, Scalar::all(255), thickness, 5); // DONT DRAW ON GRAY OR RGB IMAGES BECAUSE THEY ARE STORED FOR NEXT CYCLE
		if (trackingEnabled)
		{
			searchForMovement(thresholdImage, movingobjects);
			searchForMovement(thresholdImage2, movingobjects2);
			imshow("TrackerImage", movingobjects);
			imshow("TrackerImage2", movingobjects2);
		}
		//show our captured frame
	//	imshow("RGB1", *RGB_Buffer.current()); 
	//	imshow("RGB2", *RGB_Buffer2.current()); 
		imshow("Gray1", Gray_Buffer.current()); 
	//	imshow("Gray2", *Gray_Buffer2.current()); 
	//	imshow("Thresh1", thresholdImage);
	//	imshow("Thresh2", thresholdImage2); 
		
		
		//check to see if a button has been pressed.
		//this 10ms delay is necessary for proper operation of this program 
		//if removed, frames will not have enough time to referesh and a blank 
		//image will appear. BUT THATS FUCKING INCOMPLETE!
		char key = waitKey(5);
		switch (key) {

		case 'q': //'esc' key has been pressed, exit program.
			return 0;
		case 't': //'t' has been pressed. this will toggle tracking
			trackingEnabled = !trackingEnabled;
			if (trackingEnabled == false) cout << "Tracking disabled." << endl;
			else cout << "Tracking enabled." << endl;
			break;
		case 'd': //'d' has been pressed. this will debug mode
			debugMode = !debugMode;
			if (debugMode == false) cout << "Debug mode disabled." << endl;
			else cout << "Debug mode enabled." << endl;
			break;
		case 'p': //'p' has been pressed. this will pause/resume the code.
			pause = !pause;
			if (pause == true) {
				cout << "Code paused, press 'p' again to resume" << endl;
				while (pause == true) {
					//stay in this loop until 
					switch (waitKey()) {
						//a switch statement inside a switch statement? Mind blown.
					case 'p':
						//change pause back to false
						pause = false;
						cout << "Code Resumed" << endl;
						break;
					}
				}

			}
		case 'r' :  // refresh the drawn points
			imagecount = 0;
			imagecount2 = 0;
			RGB_Buffer.current().copyTo(movingobjects);
			RGB_Buffer2.current().copyTo(movingobjects2);
			break;
		}

	}
	//release the capture before re-opening and looping again.
//	capture.release();
//	output_cap.release();

	return 0;

}