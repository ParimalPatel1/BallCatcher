////motionTracking.cpp
//
////Written by  Kyle Hounslow, December 2013
//
////Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software")
////, to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, 
////and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
//
////The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
//
////THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
////FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER 
////LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
////IN THE SOFTWARE.
//
//#include <opencv\cv.h>
//#include  <opencv2\opencv.hpp>
//#include <Windows.h>
//#include <ctime>
//
//#include "ProjectionMethods.h"
//
//
//using namespace cv;
//using namespace std;
////#define OUTPUTCAP
//// START GLOBALS
////our sensitivity value to be used in the absdiff() function
//const static int SENSITIVITY_VALUE = 20;
////size of blur used to smooth the intensity image output from absdiff() function
//const static int BLUR_SIZE = 10;
////we'll have just one object to search for
////and keep track of its position.
//int trackedObject[2] = { 0,0 };
////bounding rectangle of the object, we will use the center of this as its position.
//
//vector<int> compression_params;
//int imagecount = 0;
//int imagecount2 = 0;
//int framecount = 0;
//int calibcount = 0;
//int movingcount = 0;
//
//#define BufferSize 2
//Point pointlist[10000];
//Point pointlist2[10000];
//int airtime_clock = 0;
//int airtime_clock2 = 0;
//bool trackingEnabled = false;
//
////Scope
//
///////////////////////////////////////////
//Mat frame; //current frame
//Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
//Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
//int keyboard; //input from keyboard
//// END GLOBALS
//template <class type>
//class CircularBuffer
//{
//public:
//	CircularBuffer() {}; // default constructor
//	CircularBuffer(int buffersize1, string name, int pixelformat) {
//		if ((buffersize1 < 1) || (buffersize1 > 100000))// check parameters
//		{
//			cout << "Error with buffersize of " << name;
//			Sleep(300000); // how to return from constructor to stop bad init?
//		}
//		// initialize class variables
//		buffersize = buffersize1;
//		bufferend = buffersize;
//		current_frame = bufferstart;
//		previous_frame = bufferend - 1;
//		next_frame = bufferstart + 1;
//		buffer = new type[buffersize];//(RESOLUTION, CV_8UC3);
//		switch (pixelformat) {
//		case 0:
//			for (int i = 0; i < buffersize; i++)
//				buffer[i] = Mat(RESOLUTION, CV_8UC3);
//			break;
//
//		case 1:
//			for (int i = 0; i < buffersize; i++)
//				buffer[i] = Mat(RESOLUTION, CV_8UC1);
//			break;
//		}
//
//
//		buffername = name;
//	};
//	~CircularBuffer() {
//		delete buffer;
//	};
//
//	type* buffer;
//	type* current_ptr;
//	type* previous_ptr;
//	type* next_ptr;
///*	int initialize(type source) // initialize the 1st element of the buffer to get things rolling
//	{
//		buffer[bufferstart] = source;
//		if (buffersize > 1)
//		{
//			buffer
//		}
//	} */
//
//	type current()
//	{
//		current_ptr = &buffer[current_frame];
//		return *current_ptr;
//	}
//	type previous()
//	{
//		previous_ptr = &buffer[previous_frame];
//		return *previous_ptr;
//	}
//	
//	type next()
//	{
//		next_ptr = &buffer[next_frame];
//		return *next_ptr;
//	}	
//	type store()
//	{
//		circulate(previous_frame);
//		circulate(current_frame);
//		circulate(next_frame);
//		return current(); //current is next, so store there. PROBLEM
//	}
//
//	void set(type &source)
//	{
//		buffer[current_frame] = source;
//	}
//
//
//	void copythis(type &copy)
//	{
//		buffer[current_frame].copyTo(copy);
//	}
//
//	void diffthis(type &diff)
//	{
//		absdiff(buffer[current_frame], buffer[previous_frame],diff);
//	}
//
//protected:
//private:
//	int buffersize = 1;
//	int previous_frame = 0;
//	int current_frame = 0;
//	int next_frame = 0;
//	int bufferstart = 0;
//	int bufferend = buffersize;
//	int source = 0;
//	string buffername = "Beef";
//	void circulate(int &a)
//	{
//		a = a + 1 == bufferend ? bufferstart : a + 1;
//	}
//
//};
//
//static inline Point calcPoint(Point2f center, double R, double angle)
//{
//	return center + Point2f((float)cos(angle), (float)-sin(angle))*(float)R;
//}
//
//class ImageSource
//{
//	public:
//		CircularBuffer<Mat>* RGB_Buffer; // = CircularBuffer<Mat>(50, "RGB_Buffer", 0); // 50 = buffersize, 0 = RGB
//		CircularBuffer<Mat>* Gray_Buffer; // = CircularBuffer<Mat>(50, "Gray_Buffer", 1); // 50 = buffersize, 1 = grayscale
//		VideoCapture cam;
//		ImageSource() {}; // default constructor
//		ImageSource(int capid, string config)
//		{
//			RGB_Buffer = new CircularBuffer<Mat>(50, "RGB_Buffer", 0); // 50 = buffersize, 0 = RGB
//			Gray_Buffer = new CircularBuffer<Mat>(50, "Gray_Buffer", 1); // 50 = buffersize, 1 = grayscale
//			cam.open(capid);
//			if (!cam.isOpened()) {
//				cout << "ERROR ACQUIRING VIDEO FEED for id " + to_string(capid) + " \n";
//				getchar();
//				//error; 
//			}
//			cam.set(CV_CAP_PROP_FRAME_WIDTH, RESOLUTION.width); // 1280 for intergrated webcam, 1080 for external webcam
//			cam.set(CV_CAP_PROP_FRAME_HEIGHT, RESOLUTION.height);
//			cam.set(CV_CAP_PROP_FPS, 30); // changes property but not camera fps 
//			////capture.set(CV_CAP_PROP_GAIN, 5);
//			////capture.set(CV_CAP_PROP_EXPOSURE, 5);
//			//	//capture.set(CV_CAP_PROP_EXPOSURE, 99); // does nothing
//			//capture.set(CV_CAP_PROP_GAIN, 5);
//			//capture.set(CV_CAP_PROP_EXPOSURE, -1);
//		}
//		ImageSource(string filepath, string config)
//		{
//			RGB_Buffer = new CircularBuffer<Mat>(50, "RGB_Buffer", 0); // 50 = buffersize, 0 = RGB
//			Gray_Buffer = new CircularBuffer<Mat>(50, "Gray_Buffer", 1); // 50 = buffersize, 1 = grayscale
//			cam.open(filepath);
//			if (!cam.isOpened()) {
//				cout << "ERROR ACQUIRING VIDEO FEED for id " + filepath + " \n";
//				getchar();
//				//error; 
//			}
//			cam.set(CV_CAP_PROP_FRAME_WIDTH, RESOLUTION.width); // 1280 for intergrated webcam, 1080 for external webcam
//			cam.set(CV_CAP_PROP_FRAME_HEIGHT, RESOLUTION.height);
//			cam.set(CV_CAP_PROP_FPS, 30); // changes property but not camera fps 
//										  ////capture.set(CV_CAP_PROP_GAIN, 5);
//										  ////capture.set(CV_CAP_PROP_EXPOSURE, 5);
//										  //	//capture.set(CV_CAP_PROP_EXPOSURE, 99); // does nothing
//										  //capture.set(CV_CAP_PROP_GAIN, 5);
//										  //capture.set(CV_CAP_PROP_EXPOSURE, -1);
//		}
//
//		~ImageSource()
//		{
//			RGB_Buffer->~CircularBuffer();
//		}
//
//};
//class ImagePipeline
//{
//public:
//	int(*detect)(Mat, Mat, Mat&);
//	int(*track)(Mat&, Mat&)
//	{
//	};
//	int(*project)(Mat, Mat, Mat&)
//	{
//	};
//	ImageSource* sources[5]; // camera limit?
//	int numofcams;
//	//camera constructor, stereo included
//	// camera constructor, no stereo
//	//ImagePipeline() {};// default constructor
//	ImagePipeline(int numcams, int capid[] = NULL, string* config = NULL, int(*detection)(Mat, Mat, Mat&) = NULL, int(*tracking)(Mat&, Mat&) = NULL, int(*projection)(Mat, Mat, Mat&) = NULL)
//	{   // parameter check
//		if (numofcams < 1 || capid == NULL || config == NULL)
//		{
//			//error
//		}
//		numofcams = numcams;
//		for (int a = 0; a < numofcams; ++a)
//		{
//			sources[a] = new ImageSource(capid[a], "");
//		}
//		detect = detection; // set object detection function
//		track = tracking; // set object tracking function
//		project = projection;
//	};
//	ImagePipeline(int numcams, string* filepaths, string* config = NULL, int(*detection)(Mat, Mat, Mat&) = NULL, int(*tracking)(Mat&, Mat&) = NULL, int(*projection)(Mat, Mat, Mat&) = NULL)
//	{   // parameter check
//		if (numofcams < 1 || filepaths == NULL || config == NULL)
//		{
//			//error
//		}
//		numofcams = numcams;
//		for (int a = 0; a < numofcams; ++a)
//		{
//			sources[a] = new ImageSource(*filepaths, "");
//		}
//		detect = detection; // set object detection function
//		track = tracking; // set object tracking function
//		project = projection;
//	};
//	~ImagePipeline()
//	{
//		for (int a = 0; a < numofcams; a++)
//			sources[a]->~ImageSource();
//	};
//	void RGBtoGray()
//	{
//		for (int a = 0; a < numofcams; a++)
//		{
//		cvtColor(sources[a]->RGB_Buffer->current(), sources[a]->Gray_Buffer->store(), COLOR_BGR2GRAY);
//		}
//	}
//
//	int cap() 
//	{	//  minimal software sychronization
//		for (int a = 0; a < numofcams; a++)
//		{ // capture frame first
//			sources[a]->cam.grab();
//		}
//		for (int a = 0; a < numofcams; a++)
//		{ // decode frame second
//			sources[a]->cam.retrieve(sources[a]->RGB_Buffer->store());
//		}
//		return 0;
//	}
//
//
//protected:
//	
//private:
//
//};
//
//void on_mouse(int e, int x, int y, int d, void *ptr)
//{
//	if (e != CV_EVENT_LBUTTONDOWN)
//		return;
//	Point*p = (Point*)ptr;
//	p->x = x;
//	p->y = y;
//}
//Mat Window(Point testpoint, Mat &testimage, Size windowsize)
//{ // assumes same pixel format of input as output
//  //Range check
///*	int rowwindow = windowsize.height / 2;
//	int colwindow = windowsize.width / 2;
//	int lowerboundrow = testpoint.x - rowwindow < 0 ? 1 : testpoint.x - rowwindow;
//	int upperboundrow = testpoint.x + rowwindow > testimage.row ? (testimage.rows) : testpoint.x + rowwindow; // WEIRD REVERSED LOGIC FIX
//	int lowerboundcolumn = testpoint.y - colwindow < 0 ? 1 : testpoint.y - colwindow;
//	int upperboundcolumn = testpoint.y + colwindow > testimage.cols ? (testimage.cols - 1) : testpoint.y + colwindow;// WEIRD REVERSED LOGIC FIX
//	Mat window = testimage(Range(lowerboundrow, upperboundrow), Range(lowerboundcolumn, upperboundcolumn));
//	return window;
//	*/
//	Mat nothing;
//	return nothing;
//}
//Mat Window(Rect rect, Mat &testimage)
//{
//	if (rect.width + rect.x > testimage.cols)
//		rect.width = testimage.cols - rect.x;
//	if (rect.height + rect.y > testimage.rows)
//		rect.height = testimage.rows - rect.y;
//	Mat window = testimage(rect);
//	return window;
//}
//
//// Search Image should be grayscale, because Houghcircles needs it to be in this format.
//int searchForCircles(Mat &SearchImage, Mat &movingobjects) {
////	Mat img = Mat(Size(SearchImage.cols, SearchImage.rows), CV_8UC1);
//	int circlesfound = 0;
//	//these two vectors needed for output of findContours
//	vector<Vec3f> circles;
//	HoughCircles(SearchImage, circles, CV_HOUGH_GRADIENT,
//		2, SearchImage.rows / 8, 200, 100); // going to be dependant on resolution and windowed image
//	circlesfound = circles.size();
//	if (circlesfound > 0)
//	{
//	for (size_t i = 0; i < circlesfound; i++)
//	{
//		Point center(cvRound(circles[i][0]), cvRound(circles[i][1]));
//		int radius = cvRound(circles[i][2]);
//		// draw the circle center
//		circle(SearchImage, center, 3, Scalar(0, 255, 0), -1, 8, 0);
//		// draw the circle outline
//		circle(SearchImage, center, radius, Scalar(0, 0, 255), 3, 8, 0);
//	}
////	imshow("circles", SearchImage);
//	// return 0, no circle
//	// return 1, one or more circles detected.
//	// need criteria for determining the ball over other found circles.
//	// use tracking to filter out none moving circles?
//	}
//	return circlesfound;
//}
//
// // finds moving objecs in an image
//int searchForMovement(Mat CurrGraySource, Mat PrevGraySource, Mat &movingobjects) {
//	Mat differenceImage;
//	Mat thresholdImage;
//	//perform frame differencing with the sequential images. 
//	absdiff(PrevGraySource, CurrGraySource, differenceImage); // order matters here
//	//imshow("diff", differenceImage);
//	//threshold intensity image at a given sensitivity value
//	threshold(differenceImage, thresholdImage, SENSITIVITY_VALUE, 255, THRESH_BINARY);
//	//blur the image to get rid of the noise. This will output an intensity image
//	blur(thresholdImage, thresholdImage, Size(BLUR_SIZE, BLUR_SIZE));
//	//threshold again to obtain binary image from blur output
//	threshold(thresholdImage, thresholdImage, SENSITIVITY_VALUE, 255, THRESH_BINARY);
//	imshow("threshold", thresholdImage);
//	bool objectDetected = false;
//	//these two vectors needed for output of findContours
//	vector< vector<Point> > contours;
//	vector<Vec4i> hierarchy;
//	Rect objectBoundingRectangle = Rect(0, 0, 0, 0);
//	//find contours of filtered image using openCV findContours function
//	//findContours(temp,contours,hierarchy,CV_RETR_CCOMP,CV_CHAIN_APPROX_SIMPLE );// retrieves all contours
//	//imwrite("thresh" + intToString(framecount) + ".png", thresholdImage);
//	findContours(thresholdImage, contours, hierarchy, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);// retrieves external contours, CHANGES THRESHOLD IMAGE
////	HoughCircles()
//	//if contours vector is not empty, we have found some objects
//	if (contours.size() > 0)
//	{
//	//	imwrite("contours" + intToString(framecount) + ".png", thresholdImage);
//		//the largest contour is found at the end of the contours vector
//		//we will simply assume that the biggest contour is the object we are looking for.
//		vector< vector<Point> > largestContourVec;
//		float circularratio;
//	//	Mat rects;
//	//	thresholdImage.copyTo(rects);
//		for (int i = contours.size() - 1; i >= 0 ; i--)
//		{ 
//			//	circlecheck(Point(contours.at(i).at(i).x, contours.at(i).at(i).y));
//			//largestContourVec.push_back(contours.at(contours.size() - 1));
//			objectBoundingRectangle = boundingRect(contours.at(i));//largestContourVec.at(0));
//			if (objectBoundingRectangle.area() > 0 && objectBoundingRectangle.area() < 50000) // SIZE CHECK DEPENDANT ON RESOLUTION
//			{
//				int xpos = objectBoundingRectangle.x + objectBoundingRectangle.width / 2;
//				int ypos = objectBoundingRectangle.y + objectBoundingRectangle.height / 2;
//				int foundcircle = 0;
//				objectBoundingRectangle.width = objectBoundingRectangle.width + 20;
//				objectBoundingRectangle.height = objectBoundingRectangle.height + 20;
//				movingobjects = Window(objectBoundingRectangle, CurrGraySource);
//				movingcount++;
//				imwrite("testimage" + to_string(movingcount) + ".png", movingobjects);
//				//movingobjects = Window(Point(xpos, ypos), CurrGraySource, Size(objectBoundingRectangle.width, objectBoundingRectangle.height));
//				foundcircle = searchForCircles(movingobjects, movingobjects);
//			//	imshow("moving objects", movingobjects);
//				if (foundcircle > 0)
//				{ // at least one circle found
//				// moving objects has one ball, start running tracking
//					imwrite("circles" + to_string(framecount) + ".png", movingobjects);
//				//	break; // stop looking?
//				}
//				//	rectangle(rects, objectBoundingRectangle, Scalar(255, 255, 255));
//			//	imshow("rect", rects);
//			//	//rectangle(movingobjects, objectBoundingRectang le, Scalar(255, 255, 255));
//			////	imwrite("rectangle" + intToString(framecount) + ".png", movingobjects);
//			//	circularratio = (float)objectBoundingRectangle.width / objectBoundingRectangle.height;
//			//	float threshold = 1; 
//			//	if (circularratio > (float)1/threshold || circularratio < (float)1*threshold)// (circularratio > 1 - threshold || circularratio < 1 + threshold)  //then roundness check
//			//	{ // we think this a moving circle now
//			//	circle(movingobjects, Point(xpos, ypos), 20, Scalar(255, 255, 255), 2);
//			//	 // make these generic structs to be passed to tracking method
//			//	pointlist[imagecount] = Point(xpos, ypos); 
//			//	if (imagecount > 0)
//			//	{
//			//		line(movingobjects, pointlist[imagecount - 1], pointlist[imagecount], Scalar(255, 255, 255), 2);
//			//	}
//			//	imagecount++;
//			//	}
//			}
//			else
//				break;
//
//		}
//	//	largestContourVec.push_back(contours.at(contours.size() - 1));
//		//make a bounding rectangle around the largest contour then find its centroid
//		//this will be the object's final estimated position.
//	//	objectBoundingRectangle = boundingRect(largestContourVec.at(0));
//		//if (objectBoundingRectangle.area() > 50 && objectBoundingRectangle.area() < 1000) // RESOLUTION DEPENDANT
//		//{
//		//	rectangle(movingobjects, objectBoundingRectangle, Scalar(255, 255, 0));
//		//}
//
//		//int circularratio = objectBoundingRectangle.width / objectBoundingRectangle.height;
//		//if (objectBoundingRectangle.area() > 30) // filter out more noise between frames // RESOLUTION DEPENDANT 
//		//{
//		//	int xpos = objectBoundingRectangle.x + objectBoundingRectangle.width / 2;
//		//	int ypos = objectBoundingRectangle.y + objectBoundingRectangle.height / 2;
//		//	
//		//	if (camera == 1)
//		//		{
//		//			pointlist[imagecount] = Point(xpos, ypos); //.at(imagecount,imagecount);
//		//			circle(movingobjects, pointlist[imagecount], 20, Scalar(255, 255, 255), 2);
//		//		/*	if (imagecount == 0)
//		//			{
//		//				airtime_clock = clock(); // start timer for first point
//		//				putText(movingobjects, "Time(ms): 0", pointlist[imagecount], 1, 1, Scalar(255, 0, 0), 2);
//		//			}
//		//			else
//		//			{
//		//				int timelaspe = clock() - airtime_clock;
//		//				putText(movingobjects, "Time(ms): " + to_string(timelaspe), pointlist[imagecount], 1, 1, Scalar(255, 0, 0), 2);
//		//			}
//		//			*/
//		//			//putText(TrackerImage, "Tracking object at (" + intToString(xpos) + "," + intToString(ypos) + ")", pointlist[imagecount], 1, 1, Scalar(255, 0, 0), 2);
//		//			if (imagecount > 0)
//		//			{
//		//				line(movingobjects, pointlist[imagecount - 1], pointlist[imagecount], Scalar(255, 255, 255), 2);
//		//			}
//		//			imagecount++;
//		//		}
//		//		if (camera == 2)
//		//		{
//		//			pointlist2[imagecount2] = Point(xpos, ypos); //.at(imagecount,imagecount);
//		//			circle(movingobjects, pointlist2[imagecount2], 20, Scalar(0, 255, 0), 2);
//		//		/*	if (imagecount2 == 0)
//		//			{
//		//				airtime_clock2 = clock(); // start timer for first point
//		//				putText(movingobjects, "Time(ms): 0", pointlist2[imagecount2], 1, 1, Scalar(255, 0, 0), 2);
//		//			}
//		//			else
//		//			{
//		//				int timelaspe = clock() - airtime_clock2;
//		//				putText(movingobjects, "Time(ms): " + to_string(timelaspe), pointlist2[imagecount2], 1, 1, Scalar(255, 0, 0), 2);
//		//			}
//		//			*/
//		//			if (imagecount2 > 0)
//		//			{
//		//				line(movingobjects, pointlist2[imagecount2 - 1], pointlist2[imagecount2], Scalar(0, 255, 0), 2);
//		//			}
//		//			imagecount2++;
//	}
//	return 1;
//}
//
//int Algorithim2(Mat GraySource1, Mat &thresholdImage) {
//	int thresh = 50;
//	
//	GaussianBlur(GraySource1, GraySource1, Size(9, 9), 2, 2);
//	Canny(GraySource1, thresholdImage, thresh, thresh * 2, 3);
//	return 0;
//}
//
//void MyCallbackForContrast(int iValueForContrast, void *userData)
//{
//	Mat dst;
//	int iValueForBrightness = *(static_cast<int*>(userData));
//
//	//Calculating brightness and contrast value
//	int iBrightness = iValueForBrightness - 50;
//	double dContrast = iValueForContrast / 50.0;
//
//	//Calculated contrast and brightness value
//	cout << "MyCallbackForContrast : Contrast=" << dContrast << ", Brightness=" << iBrightness << endl;
//
//	//adjust the brightness and contrast
//	//src.convertTo(dst, -1, dContrast, iBrightness);
//
//	//show the brightness and contrast adjusted image
//	imshow("My Window", dst);
//}
//
//int main() {
//	// START DECLARATIONS
//	//some boolean variables for added functionality
//	bool objectDetected = false;
//	//these two can be toggled by pressing 'd' or 't'
//	bool debugMode = false;
//	//pause and resume code
//	bool pause = false;
//
//	Mat differenceImage;
//	Mat thresholdImage =  Mat(RESOLUTION, CV_8UC1);
//	Mat thresholdImage2 =  Mat(RESOLUTION, CV_8UC1);
//	Mat movingobjects = Mat(RESOLUTION, CV_8UC3);
//	Mat movingobjects2 = Mat(RESOLUTION, CV_8UC3);
//	Mat* contour_drawing; 
//	
//	Point textcenter1(100, 50); // text variables start
//	Point textcenter2(100, 100);
//	Point textcenter3(100, 150);
//	int fontFace = FONT_HERSHEY_SCRIPT_SIMPLEX;
//	double fontScale = 1;
//	int thickness = 2; // text variables end
//
//	unsigned int current_time = 1;
//	float start_time = clock(); // timer variable
//	unsigned int last_time = clock();
//	unsigned int framecounter = 0;
//	int frame_start = 0;
//	float fps;
//	const string filepath = "test.avi"; //C:\Users\Benjamin\Desktop
//	VideoWriter output_cap;
//	const string videopath = "ballthrow2.avi";
//
////END DECLARATIONS
//
//// START INIT
//	//create Background Subtractor objects
//	pMOG2 = createBackgroundSubtractorMOG2 (255, 16.0, false);//MOG2 approach
//	//pMOG2 = createBackgroundSubtractorKNN(500, 400.0, false);
//
//	int capids[] = { 700,702 };
//	//int capids[1] = { 700};
//	string config = videopath;
//	//string config = "L";
//	ImagePipeline Pipeline(2, capids, &config, searchForMovement, searchForCircles); // init with webcams source
//// ImagePipeline Pipeline(1, &config, &config, searchForMovement, searchForCircles); // init with video source
//#ifdef OUTPUTCAP
//	int debug = output_cap.open(filepath,
//		CV_FOURCC_MACRO('M','J','P','G'), //YUYV
//	30, RESOLUTION, true);
//	 Sleep(100);
//	 if (!output_cap.isOpened())
//	 {
//		 cout << "!!! Output video could not be opened" << debug << "\n" 
//			 //<<
//			 //capture.get(CV_CAP_PROP_FPS) << "\n" <<
//			// capture.get(CV_CAP_PROP_FRAME_HEIGHT) << "\n" <<
//			// capture.get(CV_CAP_PROP_FRAME_WIDTH) 
//			 << endl;
//		 return -1;
//	 }
//#endif
//
//	 //Create trackbar to change contrast
//	 //int minThreshold = 0;
//	 //createTrackbar("minThreshold", "My Window", &minThreshold, 255);
//	 //Point p = Point(0,0);
//	// namedWindow("RGB");
//	 namedWindow("circles", 1);
//	 //setMouseCallback("RGB", on_mouse, &p);
//	 createTrackbars();
//
// // END INIT
//	 Pipeline.cap(); // initial frame for each buffer so previous frame is available on first loop
//	 Pipeline.RGBtoGray();
//	////////// MAIN LOOP START
//	while (1) { // capture and process loop
//		fps = 1000 / (1 + clock() - last_time); // time stuff
//		last_time = clock();
//		cout << "FPS: " << fps << endl; // faster than draw??
//		framecount++; 
//
//		Pipeline.cap();
//		Pipeline.RGBtoGray();
//		//imshow("L_RGB", Pipeline.sources[0]->RGB_Buffer->current());
//		imshow("L_GRAY", Pipeline.sources[0]->Gray_Buffer->current());
//	//	imshow("R_RGB", Pipeline.sources[1]->RGB_Buffer->current());
//		//imshow("R_GRAY", Pipeline.sources[1]->Gray_Buffer->current());
//
//		Pipeline.detect(Pipeline.sources[0]->Gray_Buffer->current(), Pipeline.sources[0]->Gray_Buffer->previous(), movingobjects);
//		imshow("circles", movingobjects);
//	
//	//	searchForCircles(thresholdImage, movingobjects);
//		//putText(*grayImage1, "FPS: " + to_string(fps), textcenter3, fontFace, fontScale, Scalar::all(255), thickness, 5); // DONT DRAW ON GRAY OR RGB IMAGES BECAUSE THEY ARE STORED FOR NEXT CYCLE
////////////// TEST CODE END /////////////////////////////
//
//#ifdef OUTPUTCAP		
//	output_cap.write(Pipeline.sources[0]->RGB_Buffer->current());
//#endif
//		// start keyboard interface
//		char key = waitKey(1);
//		switch (key) {
//		case 'q': //'esc' key has been pressed, exit program.
//			output_cap.release();
//			// add all deconstructors here?
//			return 0;
//		case 't': //'t' has been pressed. this will toggle tracking
//			trackingEnabled = !trackingEnabled;
//			if (trackingEnabled == false) cout << "Tracking disabled." << endl;
//			else cout << "Tracking enabled." << endl;
//			break;
//		case 'd': //'d' has been pressed. this will debug mode
//			debugMode = !debugMode;
//			if (debugMode == false) cout << "Debug mode disabled." << endl;
//			else cout << "Debug mode enabled." << endl;
//			break;
//		case 'p': //'p' has been pressed. this will pause/resume the code.
//			pause = !pause;
//			if (pause == true) {
//				cout << "Code paused, press 'p' again to resume" << endl;
//				while (pause == true) {
//					//stay in this loop until 
//					switch (waitKey()) {
//					case 'p':
//						//change pause back to false
//						pause = false;
//						cout << "Code Resumed" << endl;
//						break;
//					}
//				}
//			}
//		case 'r' :  // refresh the drawn points
//			imagecount = 0;
//			imagecount2 = 0;
//		//	RGB_Buffer.current().copyTo(movingobjects);
//		//	RGB_Buffer2.current().copyTo(movingobjects2);
//			break;
//		case 'c':
//			calibcount++;
//		//	imwrite("left" + to_string(calibcount) + ".jpg", RGB_Buffer.current()); // left
//		//	imwrite("right" + to_string(calibcount) + ".jpg", RGB_Buffer2.current()); // right
//			break;
//		}
//		// end keyboad interface
//	}
//	return 0;
//}
//
